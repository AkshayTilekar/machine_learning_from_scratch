{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "# Decision Tree From Scratch (ZWM - 10/09/17)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Imports (All imports here for cleanliness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-16T21:00:47.548313Z",
     "start_time": "2017-10-16T21:00:47.425400Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import math\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Version Checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-13T15:58:04.267354Z",
     "start_time": "2017-10-13T15:58:04.131899Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python Version: 3.6.2 |Anaconda, Inc.| (default, Sep 21 2017, 18:29:43) \n",
      "[GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)] \n",
      "\n",
      "Matplotlib Version: 2.0.2\n",
      "Numpy Version: 1.13.1\n",
      "Pandas Version: 0.20.3\n",
      "Scipy Version: 0.19.1\n",
      "Sklearn Version: 0.19.0\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "import matplotlib\n",
    "import sys\n",
    "import scipy\n",
    "libraries = (('Matplotlib', matplotlib), ('Numpy', np), ('Pandas', pd), ('Scipy', scipy), ('Sklearn', sklearn))\n",
    "\n",
    "print(\"Python Version:\", sys.version, '\\n')\n",
    "for lib in libraries:\n",
    "    print('{0} Version: {1}'.format(lib[0], lib[1].__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Silly function to generate the test data, just to keep it clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-16T21:00:50.520089Z",
     "start_time": "2017-10-16T21:00:50.509207Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    \"\"\"\n",
    "    Get some data, either pretend user data or the Iris dataset\n",
    "    ------\n",
    "    \"\"\"\n",
    "    # An oversimplified dataset for easy visualization while learning\n",
    "#     headers = ['referral','country','faq','age','service']\n",
    "#     my_data=[['slashdot','USA','yes',18,'None'],\n",
    "#         ['google','France','yes',17,'Premium'],\n",
    "#         ['google','France','yes',20,'Premium'],\n",
    "#         ['reddit','USA','yes',24,'Basic'],\n",
    "#         ['wiki','France','yes',23,'Basic'],\n",
    "#         ['google','UK','no',21,'Premium'],\n",
    "#         ['(direct)','New Zealand','no',12,'None'],\n",
    "#         ['(direct)','UK','no',21,'Basic'],\n",
    "#         ['google','USA','no',24,'Premium'],\n",
    "#         ['slashdot','France','yes',19,'None'],\n",
    "#         ['slashdot','UK','yes',31,'Basic'],\n",
    "#         ['reddit','USA','no',18,'None'],\n",
    "#         ['google','UK','no',18,'None'],\n",
    "#         ['wiki','UK','no',19,'None'],\n",
    "#         ['reddit','New Zealand','yes',12,'Basic'],\n",
    "#         ['slashdot','UK','no',21,'None'],\n",
    "#         ['google','UK','yes',18,'Basic'],\n",
    "#         ['wiki','France','yes',19,'Basic']]\n",
    "#     my_data = np.array(my_data)\n",
    "#     X = my_data.T[:4]\n",
    "#     y = my_data.T[-1]\n",
    "#     return X.T,y.T\n",
    "    # The Iris data set from SKLearn \n",
    "    # (http://scikit-learn.org/stable/auto_examples/datasets/plot_iris_dataset.html)\n",
    "    from sklearn.datasets import load_iris\n",
    "    iris = load_iris()\n",
    "    return iris.data, iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's actually build our tree class, using recursion!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-16T21:00:52.056574Z",
     "start_time": "2017-10-16T21:00:51.101446Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "\n",
    "class decision_tree_classifier:\n",
    "    \n",
    "    def __init__(self, max_depth = None):\n",
    "        self.tree = self.tree_split()\n",
    "        self.data_cols = None\n",
    "        self.max_depth = max_depth\n",
    "    \n",
    "    # Sub class for handling recursive nodes (only makes sense in the scope of a tree)\n",
    "    class tree_split:\n",
    "        \"\"\"\n",
    "        A sub class for handling recursive nodes. Each node will contain the value and column\n",
    "        for the current split, as well as links to the resulting nodes from the split. The \n",
    "        results attribute remains empty unless the current node is a leaf. \n",
    "        \"\"\"\n",
    "        def __init__(self,col=-1,value=None,results=None,label=None,tb=None,fb=None):\n",
    "            self.col=col # column index of criteria being tested\n",
    "            self.value=value # vlaue necessary to get a true result\n",
    "            self.results=results # dict of results for a branch, None for everything except endpoints\n",
    "            self.tb=tb # true decision nodes \n",
    "            self.fb=fb # false decision nodes\n",
    "    \n",
    "    def split_data(self, X, y, colnum, value):\n",
    "        \"\"\"\n",
    "        Returns: Two sets of data from the initial data. Set 1 contains those that passed\n",
    "        the condition of data[colnum] >= value\n",
    "        ----------\n",
    "        Input: The dataset, the column to split on, the value on which to split\n",
    "        \"\"\"\n",
    "        splitter = None\n",
    "        if isinstance(value, int) or isinstance(value,float):\n",
    "            splitter = lambda x: x[colnum] >= value\n",
    "        else:\n",
    "            splitter = lambda x: x[colnum] == value\n",
    "        split1 = [i for i,row in enumerate(X) if splitter(row)]\n",
    "        split2 = [i for i,row in enumerate(X) if not splitter(row)]\n",
    "        set1X = X[split1]\n",
    "        set1Y = y[split1]\n",
    "        set2X = X[split2]\n",
    "        set2Y = y[split2]\n",
    "        return set1X, set1Y, set2X, set2Y\n",
    "\n",
    "    def count_target_values(self, data):\n",
    "        \"\"\"\n",
    "        Returns: A dictionary of target variable counts in the data\n",
    "        \"\"\"\n",
    "        results = {}\n",
    "        for row in data:\n",
    "            if row not in results:\n",
    "                results[row] = 0\n",
    "            results[row] += 1\n",
    "        return results\n",
    "\n",
    "    def entropy(self, y):\n",
    "        \"\"\"\n",
    "        Returns: Entropy of the data set, based on target values. \n",
    "        ent = Sum(-p_i Log(p_i), i in unique targets) where p is the percentage of the\n",
    "        data with the ith label.\n",
    "        Sidenote: We're using entropy as our measure of good splits. It corresponds to \n",
    "        information gained by making this split. If the split results in only one target type\n",
    "        then the entropy new sets entropy is 0. If it results in a ton of different targets, the\n",
    "        entropy will be high. \n",
    "        \"\"\"\n",
    "        results = self.count_target_values(y)\n",
    "        log_base = len(results.keys())\n",
    "        if log_base < 2:\n",
    "            log_base = 2\n",
    "        logb=lambda x:math.log(x)/math.log(log_base)\n",
    "        ent=0.\n",
    "        for r in results.keys():\n",
    "            p=float(results[r])/len(y) \n",
    "            ent-=p*logb(p)\n",
    "        return ent  \n",
    "    \n",
    "    def pandas_to_numpy(self, x):\n",
    "        \"\"\"\n",
    "        Checks if the input is a Dataframe or series, converts to numpy matrix for\n",
    "        calculation purposes.\n",
    "        ---\n",
    "        Input: X (array, dataframe, or series)\n",
    "        \n",
    "        Output: X (array)\n",
    "        \"\"\"\n",
    "        if type(x) == type(pd.DataFrame()) or type(x) == type(pd.Series()):\n",
    "            return x.as_matrix()\n",
    "        if type(x) == type(np.array([1,2])):\n",
    "            return x\n",
    "        return np.array(x)\n",
    "    \n",
    "    def check_feature_shape(self, x):\n",
    "        \"\"\"\n",
    "        Helper function to make sure any new data conforms to the fit data shape\n",
    "        ---\n",
    "        In: numpy array, (unknown shape)\n",
    "        Out: numpy array, shape: (rows, self.data_cols)\"\"\"\n",
    "        return x.reshape(-1,self.data_cols)\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Helper function to wrap the fit method. This makes sure the full nested, \n",
    "        recursively built tree gets assigned to the correct variable name and \n",
    "        persists after training.\n",
    "        \"\"\"\n",
    "        self.tree = self._fit(X,y)\n",
    "    \n",
    "    def _fit(self, X, y, depth=0):\n",
    "        \"\"\"\n",
    "        Builds the decision tree via a greedy approach, checking every possible\n",
    "        branch for the best current decision. Decision strength is measured by\n",
    "        information gain/entropy reduction. If no information gain is possible,\n",
    "        sets a leaf node. Recursive calls to this method allow the nesting. If\n",
    "        max_depth is met, all further nodes become leaves as well.\n",
    "        ---\n",
    "        Input: X (feature matrix), y (labels)\n",
    "        Output: A nested tree built upon the node class.\"\"\"\n",
    "        X = self.pandas_to_numpy(X)\n",
    "        y = self.pandas_to_numpy(y)\n",
    "        if not self.data_cols:\n",
    "            self.data_cols = X.shape[1]\n",
    "        self.check_feature_shape(X)\n",
    "        if len(X) == 0: return tree_split()\n",
    "        current_score = self.entropy(y)\n",
    "\n",
    "        best_gain = 0.0\n",
    "        best_criteria = None\n",
    "        best_sets = None\n",
    "        \n",
    "        cols = X.shape[1]\n",
    "        \n",
    "        \n",
    "        # Here we go through column by column and try every possible split, measuring the\n",
    "        # information gain. We keep track of the best split then use that to send the split\n",
    "        # data sets into the next phase of splitting.\n",
    "        \n",
    "        for col in range(cols):\n",
    "            \n",
    "            # find different values in this column\n",
    "            column_values = set(X.T[col])\n",
    "            # for each possible value, try to divide on that value\n",
    "            for value in column_values:\n",
    "                set1, set1_y, set2, set2_y = self.split_data(X, y, col, value)\n",
    "\n",
    "                # Information gain\n",
    "                p = float(len(set1)) / len(y)\n",
    "                gain = current_score - p*self.entropy(set1_y) - (1-p)*self.entropy(set2_y)\n",
    "                if gain > best_gain and len(set1_y) and len(set2_y):\n",
    "                    best_gain = gain\n",
    "                    best_criteria = (col, value)\n",
    "                    best_sets = (np.array(set1), np.array(set1_y), np.array(set2), np.array(set2_y))\n",
    "        \n",
    "        \n",
    "        # Now decide whether it's an endpoint or we need to split again.\n",
    "        if (self.max_depth and depth < self.max_depth) or not self.max_depth:\n",
    "            if best_gain > 0:\n",
    "                true_branch = self._fit(best_sets[0], best_sets[1], depth=depth+1)\n",
    "                false_branch = self._fit(best_sets[2], best_sets[3], depth=depth+1)\n",
    "                return self.tree_split(col=best_criteria[0], value=best_criteria[1],\n",
    "                        tb=true_branch, fb=false_branch)\n",
    "            else:\n",
    "                return self.tree_split(results=self.count_target_values(y))\n",
    "        else:\n",
    "            return self.tree_split(results=self.count_target_values(y))\n",
    "\n",
    "    def print_tree(self, indent=\"---\"):\n",
    "        \"\"\"\n",
    "        Helper function to make sure the correct tree gets printed.\n",
    "        ---\n",
    "        In: indent (how to show splits between nodes)\n",
    "        \"\"\"\n",
    "        self.__original_indent = indent\n",
    "        self._print_tree_(self.tree, indent)\n",
    "    \n",
    "    def _print_tree_(self, tree, indent):\n",
    "        \"\"\"\n",
    "        Goes through node by node and reports the column and value used to split\n",
    "        at that node. All sub-nodes are drawn in sequence below the node.\n",
    "        \"\"\"\n",
    "        if tree.results: # if this is a end node\n",
    "            print(str(tree.results))\n",
    "        else:\n",
    "            print('Column ' + str(tree.col)+' : '+str(tree.value)+'? ')\n",
    "            # Print the branches\n",
    "            print(indent+' True: ', end=' ')\n",
    "            next_indent = indent+self.__original_indent\n",
    "            self._print_tree_(tree.tb,indent=next_indent)\n",
    "            print(indent+' False: ', end=' ')\n",
    "            self._print_tree_(tree.fb,indent=next_indent)\n",
    "\n",
    "    def predict(self, newdata):\n",
    "        \"\"\"\n",
    "        Helper function to make sure the correct tree is used to\n",
    "        make predictions. Also manages multiple rows of input data\n",
    "        since the tree must predict one at a time.\n",
    "        ---\n",
    "        In: new data point of the same structure as the training X.\n",
    "        Out: numpy array of the resulting predictions\n",
    "        \"\"\"\n",
    "        results = []\n",
    "        for x in newdata:\n",
    "            results.append(self._predict(x,self.tree))\n",
    "        return np.array(results)\n",
    "            \n",
    "    def _predict(self, newdata, tree):\n",
    "        \"\"\"\n",
    "        Uses the reusive structure of the tree to follow each split for\n",
    "        a new data point. If the node is an endpoint, the available classes\n",
    "        are sorted by \"most common\" and then the top choice is returned.\n",
    "        \"\"\"\n",
    "        newdata = self.pandas_to_numpy(newdata)\n",
    "        if tree.results: # if this is a end node\n",
    "            return sorted(list(tree.results.items()), key=lambda x: x[1],reverse=True)[0][0]\n",
    "\n",
    "        if isinstance(newdata[tree.col], int) or isinstance(newdata[tree.col],float):\n",
    "            if newdata[tree.col] >= tree.value:\n",
    "                return self._predict(newdata, tree.tb)\n",
    "\n",
    "            else:\n",
    "                return self._predict(newdata, tree.fb)\n",
    "        else:\n",
    "            if newdata[tree.col] == tree.value:\n",
    "                return self._predict(newdata, tree.tb)\n",
    "            else:\n",
    "                return self._predict(newdata, tree.fb) \n",
    "\n",
    "    def score(self, X, y):\n",
    "        \"\"\"\n",
    "        Uses the predict method to measure the accuracy of the model.\n",
    "        ---\n",
    "        In: X (list or array), feature matrix; y (list or array) labels\n",
    "        Out: accuracy (float)\n",
    "        \"\"\"\n",
    "        pred = self.predict(X)\n",
    "        correct = 0\n",
    "        for i,j in zip(y,pred):\n",
    "            if i == j:\n",
    "                correct+=1\n",
    "        return float(correct)/float(len(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actually get the data, train, test, and report accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-16T21:00:52.322821Z",
     "start_time": "2017-10-16T21:00:52.058479Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5.4  3.7  1.5  0.2]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "X,y = get_data()\n",
    "print(X[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-16T21:00:52.963902Z",
     "start_time": "2017-10-16T21:00:52.865959Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dt = decision_tree_classifier(max_depth=5)\n",
    "dt.fit(pd.DataFrame(X),pd.Series(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-16T21:00:53.400023Z",
     "start_time": "2017-10-16T21:00:53.389741Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.data_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-16T21:00:54.466786Z",
     "start_time": "2017-10-16T21:00:54.453180Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 3 : 0.6? \n",
      "--- True:  Column 3 : 1.8? \n",
      "------ True:  Column 2 : 4.9? \n",
      "--------- True:  {2: 43}\n",
      "--------- False:  Column 0 : 6.0? \n",
      "------------ True:  {2: 2}\n",
      "------------ False:  {1: 1}\n",
      "------ False:  Column 2 : 5.0? \n",
      "--------- True:  Column 3 : 1.6? \n",
      "------------ True:  Column 0 : 7.2? \n",
      "--------------- True:  {2: 1}\n",
      "--------------- False:  {1: 2}\n",
      "------------ False:  {2: 3}\n",
      "--------- False:  Column 0 : 5.1? \n",
      "------------ True:  {1: 44}\n",
      "------------ False:  Column 1 : 2.5? \n",
      "--------------- True:  {0: 1, 2: 1}\n",
      "--------------- False:  {1: 3}\n",
      "--- False:  {0: 49}\n"
     ]
    }
   ],
   "source": [
    "dt.print_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-16T21:01:00.814380Z",
     "start_time": "2017-10-16T21:01:00.802686Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shuffle_data(X, y):\n",
    "    assert len(X) == len(y)\n",
    "    permute = np.random.permutation(len(y))\n",
    "    return X[permute], y[permute]\n",
    "\n",
    "def train_test_split_manual(X, y, test_size=0.3):\n",
    "    nX, ny = shuffle_data(X,y)\n",
    "    split_index = int(len(X)*test_size)\n",
    "    testX = nX[:split_index]\n",
    "    trainX = nX[split_index:]\n",
    "    testy = ny[:split_index]\n",
    "    trainy = ny[split_index:]\n",
    "    return trainX, testX, trainy, testy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-16T21:01:01.148739Z",
     "start_time": "2017-10-16T21:01:01.144309Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split_manual(X,y,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-16T21:01:01.703770Z",
     "start_time": "2017-10-16T21:01:01.571454Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9333333333333333"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = decision_tree_classifier(max_depth=5)\n",
    "dt.fit(x_train,y_train)\n",
    "dt.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-16T21:01:04.073058Z",
     "start_time": "2017-10-16T21:01:04.009381Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 2, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 0, 0, 2, 2, 2, 1, 1, 1,\n",
       "       0, 0, 2, 1, 1, 0, 2, 2, 1, 1, 0, 1, 0, 1, 0, 2, 1, 0, 1, 0, 0, 1])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = dt.predict(x_test)\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare with SkLearn Classifiers (\"professional\" trees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-16T21:01:06.174871Z",
     "start_time": "2017-10-16T21:01:05.963606Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree from SkLearn: 0.955555555556\n",
      "Accuracy of Random Forest from SkLearn: 0.911111111111\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris\n",
    "X, Y = load_iris().data, load_iris().target\n",
    "\n",
    "sktree = DecisionTreeClassifier(criterion='entropy', max_depth=5)\n",
    "skrf = RandomForestClassifier(n_estimators = 100,criterion='entropy', max_depth=5)\n",
    "\n",
    "sktree.fit(x_train,y_train)\n",
    "skrf.fit(x_train,y_train)\n",
    "\n",
    "print(\"Accuracy of Decision Tree from SkLearn: \" + str(sktree.score(x_test,y_test)))\n",
    "print(\"Accuracy of Random Forest from SkLearn: \" + str(skrf.score(x_test,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
